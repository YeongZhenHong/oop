"""! 
@file BotAPI.py
@author Liani Aslam 2609807A
@version 1.0
@brief This file contains the BotAPI class
@section DESCRIPTION
Allows the all the classes to interact with the database
"""

import mysql.connector
import Auth_Token
import datetime
import pandas as pd


class BotAPI:
    """!
    @section ABOUT
    Static variables cnx and cursor are used to open and close connections 
    from each time the other classes attempt to make a database connection
    This is to ensure that the database connection is closed after each time 
    the user is done with their commit
    Defines a telegram bot object to allow TelegramBot class to interact with the database
    to insert and retrieve crawled data from the database
    """

    def __init__(self):
        """! BotAPI class initializer
        @brief initalises static variables BotAPI.cnx and BotAPI.cursor
        """
        super().__init__()
        BotAPI.cnx = ""
        BotAPI.cursor = ""

    def openCnx(self):
        """! Open Connections
        @brief openCnx opens a database connection the the local database
        to the user to select, insert or delete data in the database
        cnx contains the database object using python mysql connector
        creates a cursor object to allow the program to execute user comamnds

        """
        self.cnx = mysql.connector.connect(user=Auth_Token.MYSQL_DBUSER,
                                           host=Auth_Token.MYSQL_HOST,
                                           database=Auth_Token.MYSQL_DBNAME,
                                           password=Auth_Token.MYSQL_PASSWD)
        self.cursor = self.cnx.cursor()

    def closeCnx(self):
        """! closeCnx(self)  
        @brief closes the database connection after commit is completed
        @brief Ensures that each time user commits to database to release all database 
        resources
        @brief cnx.close() closes the database connection
        @brief cnx.cursor.close() frees up the cursor resource that is currently 
        used by the application
        """
        self.cnx.close()  # closes the database connection
        self.cursor.close()  # closes the database connection

    def selectDB(self, platform):
        """! Select all comments that is stored in the database
        @brief Select statement to select all tweets 
        @return tuple(dataList,len(datalist)) returns tuple with an array and an integer count
        """
        dataList = []
        try:
            query = "SELECT* FROM crawler."+platform
            self.cursor.execute(query)
            dataList = [item for item in self.cursor]
            return dataList, len(dataList)
        except:
            print("No data selected!")
            return []

    def __insertTweets(self, author, content, date, likes, retweets, url):
        """! insert tweets
        @brief Inserts tweets from csv file that is generated by TwitterBot.py
        @param author Author of tweet
        @param content Content of tweet
        @param date Date tweeted
        @param likes Number of likes the tweets has
        @param retweets Number of retweets the tweet has
        @param url The URL of the tweet
        @exception self.cnx.commit() failure to commit tweets into database
        """
        try:
            add_tweets = ("INSERT INTO crawler.tweets " +
                          "(author, content, date, likes, retweets, url)" +
                          "VALUES ('"+author+"', '"+content+"', '"+date+"', '"+likes+"', '"+retweets+"', '"+url+"')")
            self.cursor.execute(add_tweets)
            self.cnx.commit()
            print("Insert Tweets Successfully!")
        except:
            print("Fail to insert into database!")

    def __insertReddit(self, comment, datetime):
        """! Insert Reddit
        @brief Insert the crawled reddit comments from csv that is generated from RedditCrawler.py
        @param comment Crawled comments
        @param datetime The date and time of crawled comments
        @exception self.cnx.commit() fail to commit the comments into database
        """
        try:
            add_reddit = ("INSERT INTO crawler.Reddit" +
                          "(comment,datetime) VALUES('" + comment+"','"+datetime+"')")
            self.cursor.execute(add_reddit)
            self.cnx.commit()
            print("Insert Reddit comments successfully!")
            return True
        except:
            print("Fail to insert Reddit comments!")
            return False

    def __insertInstagram(self, user, posts):
        """! Insert Instagram
        @brief Insert the crawled instagram comments from csv that is generated from InstagramCrawler.py
        @param user Username of the user that has posted the comment
        @param posts Comments that the user has made on the post
        """
        try:
            add_instagram = ("INSERT INTO crawler.Instagram" +
                             "(user,posts) VALUES('"+user+"','"+posts+"')")
            self.cursor.execute(add_instagram)
            self.cnx.commit()
            print("Insert Instagram posts successfully!")
            return True
        except:
            print("Fail to insert Instagram posts!")
            return False

    def readCsv(self, platform, socialMedia):
        """! Inserts generated csv files from crawlers into database
        @param fileType A String value of either Twitter,Reddit or Yahoo to insert into different db
        @exception fail to read csv files
        """

        if(socialMedia == "Twitter"):
            try:
                df = pd.read_csv("./CSV/"+platform+"_Twitter.csv", usecols=[
                    'content', 'author', 'date', 'retweets', 'likes', 'url'])
                for index, row in df.iterrows():
                    self.__insertTweets(str(row['author']), str(row['content']), str(
                        row['date']), str(row['likes']), str(row['retweets']), str(row['url']))
                return True
            except:
                print("Fail to read Twitter csv")
                return False
        elif(socialMedia == "Reddit"):
            try:
                df = pd.read_csv("./CSV/"+platform+"_Reddit.csv", usecols=[
                    'Comment', 'Datetime'])
                for index, row in df.iterrows():
                    self.__insertReddit(
                        str(row['Comment']), str(row['Datetime']))
                return True
            except:
                print("Fail to read Reddit CSV")
                return False
        elif(socialMedia == "Instagram"):
            try:
                df = pd.read_csv("./CSV/"+platform+"_Instagram.csv", usecols=['user', 'posts'])
                for index, row in df.iterrows():
                    self.__insertInstagram(str(row['user']), str(row['posts']))
                return True
            except:
                print("Fail to read Instagram csv")
                return False

a = BotAPI()
a.openCnx()
a.readCsv("GrabFood","Twitter")
a.readCsv("GrabFood","Reddit")
a.readCsv("GrabFood","Instagram")
a.closeCnx()